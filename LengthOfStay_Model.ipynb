{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzT6yThnjEht",
        "outputId": "792c0369-1c14-41f2-802d-31ea9ffdcc75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\proah\\AppData\\Local\\Temp\\ipykernel_22844\\2715890615.py:2: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'LengthOfStay.csv'  # Replace with your file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'vdate'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\proah\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[1;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'vdate'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 1: Data Preprocessing\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Convert date columns to datetime format\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdischarged\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdischarged\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Create new features from the date columns (e.g., year, month)\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\proah\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[1;32mc:\\Users\\proah\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3807\u001b[0m     ):\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'vdate'"
          ]
        }
      ],
      "source": [
        "# Step 1: Data Preprocessing\n",
        "\n",
        "# Convert date columns to datetime format\n",
        "df['vdate'] = pd.to_datetime(df['vdate'], errors='coerce')\n",
        "df['discharged'] = pd.to_datetime(df['discharged'], errors='coerce')\n",
        "\n",
        "# Create new features from the date columns (e.g., year, month)\n",
        "df['vdate_year'] = df['vdate'].dt.year\n",
        "df['vdate_month'] = df['vdate'].dt.month\n",
        "df['discharged_year'] = df['discharged'].dt.year\n",
        "df['discharged_month'] = df['discharged'].dt.month\n",
        "\n",
        "# Drop the original date columns\n",
        "df = df.drop(columns=['vdate', 'discharged'])\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "df['gender'] = label_encoder.fit_transform(df['gender'])\n",
        "df['rcount'] = label_encoder.fit_transform(df['rcount'])\n",
        "df['facid'] = label_encoder.fit_transform(df['facid'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Handling Missing Values in Target Variable\n",
        "\n",
        "# Drop rows where the target variable 'lengthofstay' is NaN\n",
        "df = df.dropna(subset=['lengthofstay'])\n",
        "\n",
        "# Step 3: Splitting Data into Features and Target\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df.drop(columns=['lengthofstay', 'eid'])  # Features (excluding 'eid' and target)\n",
        "y = df['lengthofstay']  # Target\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Train-Test Split\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 0.40142654499999997\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Model Training and Testing\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model using Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM_d7Hhvkoa7",
        "outputId": "67ad8473-47a9-4e2f-e01e-91ca64e3224b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R-squared: 0.926843051265384\n",
            "Root Mean Squared Error: 0.6335823111482832\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Calculate R-squared\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Calculate RMSE (Root Mean Squared Error)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f'R-squared: {r2}')\n",
        "print(f'Root Mean Squared Error: {rmse}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig-mbmXVmxtD",
        "outputId": "f756ccb3-d343-4d36-f6f7-6fab69c5c75b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 59\u001b[0m\n\u001b[0;32m     27\u001b[0m input_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrcount\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m],  \u001b[38;5;66;03m# Replace with actual value for one patient\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m],  \u001b[38;5;66;03m# Replace with actual gender encoded value for one patient\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdischarged_month\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m     56\u001b[0m })\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Make predictions for a single patient\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m predicted_length_of_stay \u001b[38;5;241m=\u001b[39m predict_length_of_stay(\u001b[43mmodel\u001b[49m, input_data, feature_columns)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Length of Stay:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_length_of_stay[\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Output the prediction for the single patient\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# Step 6: Function to make predictions based on specific columns\n",
        "def predict_length_of_stay(model, input_data, feature_columns):\n",
        "    \"\"\"Predict the length of stay based on the specified input features.\"\"\"\n",
        "    if any(col not in input_data.columns for col in feature_columns):\n",
        "        raise ValueError(\"One or more specified columns are not in the input data.\")\n",
        "\n",
        "    # Select the relevant features from the input data\n",
        "    input_features = input_data[feature_columns]\n",
        "\n",
        "    # Make predictions using the model\n",
        "    predictions = model.predict(input_features)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Specify the complete list of feature columns\n",
        "feature_columns = [\n",
        "    'rcount', 'gender', 'dialysisrenalendstage', 'asthma', 'irondef',\n",
        "    'pneum', 'substancedependence', 'psychologicaldisordermajor',\n",
        "    'depress', 'psychother', 'fibrosisandother', 'malnutrition',\n",
        "    'hemo', 'hematocrit', 'neutrophils', 'sodium', 'glucose',\n",
        "    'bloodureanitro', 'creatinine', 'bmi', 'pulse', 'respiration',\n",
        "    'secondarydiagnosisnonicd9', 'facid', 'vdate_year',\n",
        "    'vdate_month', 'discharged_year', 'discharged_month'\n",
        "]\n",
        "\n",
        "# Create a new DataFrame for a single patient prediction with all necessary columns\n",
        "input_data = pd.DataFrame({\n",
        "    'rcount': [1],  # Replace with actual value for one patient\n",
        "    'gender': [1],  # Replace with actual gender encoded value for one patient\n",
        "    'dialysisrenalendstage': [0],  # Replace with actual value for one patient\n",
        "    'asthma': [1],  # Replace with actual value for one patient\n",
        "    'irondef': [0],  # Replace with actual value for one patient\n",
        "    'pneum': [0],  # Replace with actual value for one patient\n",
        "    'substancedependence': [0],  # Replace with actual value for one patient\n",
        "    'psychologicaldisordermajor': [1],  # Replace with actual value for one patient\n",
        "    'depress': [0],  # Replace with actual value for one patient\n",
        "    'psychother': [0],  # Replace with actual value for one patient\n",
        "    'fibrosisandother': [1],  # Replace with actual value for one patient\n",
        "    'malnutrition': [0],  # Replace with actual value for one patient\n",
        "    'hemo': [12],  # Replace with actual value for one patient\n",
        "    'hematocrit': [40],  # Replace with actual value for one patient\n",
        "    'neutrophils': [6.5],  # Replace with actual value for one patient\n",
        "    'sodium': [140],  # Replace with actual value for one patient\n",
        "    'glucose': [90],  # Replace with actual value for one patient\n",
        "    'bloodureanitro': [0.5],  # Replace with actual value for one patient\n",
        "    'creatinine': [1.0],  # Replace with actual value for one patient\n",
        "    'bmi': [22.5],  # Replace with actual value for one patient\n",
        "    'pulse': [72],  # Replace with actual value for one patient\n",
        "    'respiration': [16],  # Replace with actual value for one patient\n",
        "    'secondarydiagnosisnonicd9': [0],  # Replace with actual value for one patient\n",
        "    'facid': [5],  # Replace with actual facid encoded value for one patient\n",
        "    'vdate_year': [2023],\n",
        "    'vdate_month': [10],\n",
        "    'discharged_year': [2023],\n",
        "    'discharged_month': [10],\n",
        "})\n",
        "\n",
        "# Make predictions for a single patient\n",
        "predicted_length_of_stay = predict_length_of_stay(model, input_data, feature_columns)\n",
        "print(\"Predicted Length of Stay:\", predicted_length_of_stay[0])  # Output the prediction for the single patient\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming your trained model is stored in a variable called `model`\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(\u001b[43mmodel\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_of_stay_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_of_stay_model_compressed.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, compress\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Assuming your trained model is stored in a variable called `model`\n",
        "joblib.dump(model, 'length_of_stay_model.pkl')\n",
        "joblib.dump(model, 'length_of_stay_model_compressed.pkl', compress=3)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
